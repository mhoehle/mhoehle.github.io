<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Is the answer to everything Gaussian?</title>
  <meta name="description" content="Abstract:">

  <link rel="stylesheet" href="/blog/css/main.css">
  <link rel="canonical" href="https://mhoehle.github.io/blog/2018/10/29/gauss.html">
  <link rel="alternate" type="application/rss+xml" title="Theory meets practice..." href="https://mhoehle.github.io/blog/feed.xml">
</head>

<!-- https://docs.mathjax.org/en/v2.7-latest/start.html -->
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>




  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/blog/">Theory meets practice...</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/blog/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Is the answer to everything Gaussian?</h1>
    <p class="post-meta"><time datetime="2018-10-29T00:00:00+01:00" itemprop="datePublished">Oct 29, 2018</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h2 id="abstract">Abstract:</h2>
<p>As an applied statistician you get in touch with many challenging
problems in need of a statistical solution. Often, your client/colleague
already has a working solution and just wants to clarify a small
statistical detail with you. Equally often, your intuition suggests you
that the working solution is not statistically adequate, but how to
substantiate this? As motivating example we use the statistical process
control methodology used in <span class="citation"
data-cites="sarma_etal2018">Sarma et al. (2018)</span> for monitoring a
binomial proportion as part of a syndromic surveillance kit.</p>
<center>
<img src="/blog/figure/source/2018-10-29-gauss/fig1a-hilight.png" width="600">
</center>
<p><br>
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png"/></a>
This work is licensed under a <a rel="license"
href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons
Attribution-ShareAlike 4.0 International License</a>. The
markdown+Rknitr source code of this blog is available under a <a
href="https://www.gnu.org/licenses/gpl-3.0.html">GNU General Public
License (GPL v3)</a> license from github.</p>
<h2 id="introduction">Introduction</h2>
<p>A few weeks ago I became aware of the publication by <span
class="citation" data-cites="sarma_etal2018">Sarma et al. (2018)</span>
who, as part of a syndromic surveillance system, monitor the time series
of a proportion with the aim of timely detecting changes. What initially
caught my intention was their figure 1A:</p>
<center>
<img src="/blog/figure/source/2018-10-29-gauss/fig1a.png" width="600">
</center>
<FONT COLOR="bbbbbb">Figure : Figure 1A from <span class="citation"
data-cites="sarma_etal2018">Sarma et al. (2018)</span> showing the time
series of proportions that reports of acute respiratory infection make
up of all syndrome reports that day. </FONT>
<p>
<p>Reading the details of the paper reveals that the number of daily
counts on 14 syndromes is collected and for each syndrome the proportion
of the particular syndrome out of all syndrome reports is calculated. In
other words: given that the counts for a particular day <span
class="math inline">\(t\)</span> are <span class="math inline">\(y_{it},
i=1, \ldots, 14\)</span>, the monitored proportion is <span
class="math inline">\(p_{it} = y_{it}/\sum_{j=1}^{14} y_{jt}\)</span>.
It is thus clear that it’s impossible to get beyond 100%. The more
surprising was that the upper level in the figure goes beyond it - a
sign of an inadequate statistical method. What the authors do is to
compute an upper threshold for a particular day <span
class="math inline">\(t_{0}\)</span> as follows:</p>
<p><span class="math display">\[
U_{t_0} = \overline{p}_{t_0}(d) + k \cdot s_{t_0}(d), \quad
\text{where}\\
\quad \overline{p}_{t_0}(d) = \frac{1}{d}\sum_{t=t_0-d}^{t_0-1} p_{t}
\quad\text{and}\quad
s_{t_0}(d) = \frac{1}{d-1} \sum_{t=t_0-d}^{t_0-1}
(p_{t} - \overline{p}_{t_0}(d))^2
\]</span></p>
<p>is the mean and standard deviation of the <span
class="math inline">\(d\)</span> baseline observations<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>,
respectively, and <span class="math inline">\(k\)</span> is a tuning
parameter - for 12 out of the 14 syndromes <span
class="math inline">\(k=2\)</span> is used, but for the two syndromes
with highest proportions, including acute respiratory infections, <span
class="math inline">\(k=4\)</span> is used. As the method looks like an
adaptation of the simple EARS method <span class="citation"
data-cites="fricker_etal2008">(Fricker, Hegler, and Dunfee 2008)</span>
to proportions, this caused me to tweet the following critical remark
(no harm intended besides the scientific criticism of using a somewhat
inadequate statistical method):</p>
<center>
<img src="/blog/figure/source/2018-10-29-gauss/tweet1.png" width="600">
</center>
<p>To which one of the authors, <a
href="https://twitter.com/evolution_v2">Alexander Ullrich</a>,
replied</p>
<center>
<img src="/blog/figure/source/2018-10-29-gauss/tweet2.png" width="600">
</center>
<p>
<p>Initially, I replied by twitter, but realized that twitter is not a
good format for a well-balanced and thorough scientific discourse. Also,
my answers lacked exemplification and supporting numbers, so I deleted
the answers and shall instead use this blog post to provide a thorough
answer. Please note that my discussion focuses on the paper’s
statistical methodology approach - I do think the published application
is very important and I’m happy to see that the resulting Excel tool is
made available to a greater audience under a creative common
license!</p>
<p>As much I can understand the motives, working in applied statistics
is always a balance between mathematical exactness and pragmatism. A <a
href="https://quoteinvestigator.com/2011/05/13/einstein-simple/">famous
quote</a> says that things should be as simple as possible, but not
simpler. But if mathematical rigour always comes in second place,
something is amiss. In this light, I’d like to comment on the four
reasons given in Alexander’s reply.</p>
<h3 id="reason-1-2">Reason 1 &amp; 2:</h3>
<p>In principle I agree and taking a non-parametric and distribution
free approach is healthy, if you fear your assumptions are more quickly
violated than you can formulate them. Using the mean plus two times
standard deviation of the <span class="math inline">\(d=15\)</span>
baseline proportions does, however, imply certain assumptions. It means
that you believe i the distribution being sufficiently stable that the
expectation and standard deviation estimated from the baseline values is
indicative for the next observation’s expectation and standard
deviation. In other words: no trends, no day of the week effects and no
previous outbreaks are allowed in the baseline. Looking at the jump of
the upper-bound line after the single peak in June 2016 in Fig 1A one
concludes that this might be a problematic assumption. Furthermore, one
assumes that the distribution is sufficiently symmetric such that its
quantiles can be described as a number of times the standard deviations
away from the mean. Finally, by using the usual formula to estimate the
standard deviation one assumes that the observations are independent.
They are likely not and, hence, the estimated standard deviation might
be too small. All these limitations need to be mentioned and are
probably the biggest problem with the method, but could be addressed by
semi-simple modelling approaches as done, e.g., in <span
class="citation"
data-cites="farrington96">(<strong>farrington96?</strong>)</span> for
counts.</p>
<p>For the remainder of this post, I shall instead focus on using the
mean plus two times standard deviation (sd) rule, as I have seen it too
many times - also in other surveilance contexts. The problem we are
solving <em>is</em> a statistical one, so writing that the
k-times-sd-rule is not meant to have a probabilistic interpretation
leaves the user alone with the choice of threshold. In particular many
users will know from their Statistics 101 class that mean plus/minus two
times sd is as a way to get approximately 95% of the mass for anything
which has a Gaussian shape. Due to the <strong>central limit
theorem</strong> this shape will apply to a certain degree.</p>
<p>So what we do is to compare an out-of-sample observation with a
threshold. In this case the <strong>prediction interval</strong> for the
observation is the statistical correct object for the comparison.
Because the standard deviation is estimated from data, the prediction
interval should be based on quantiles of a t-distribution with <span
class="math inline">\(d-1\)</span> degrees of freedom. In this case the
appropriate upper limit of a two-sided <span
class="math inline">\((1-\alpha)\cdot 100%\)</span> prediction interval
is given as</p>
<p><span class="math display">\[
\begin{align} \label{eq:predict-ul-gauss} \
U_{t_0} = \overline{p}_{t_0}(d) +
  t_{1-\alpha/2}(d-1) \cdot \sqrt{1+\frac{1}{d}} \cdot s_{t_0}(d),
  \end{align}
\]</span> where <span class="math inline">\(t_{1-\alpha/2}(d-1)\)</span>
denotes the <span class="math inline">\(1-\alpha/2\)</span> quantile of
the t-distribution with <span class="math inline">\(d-1\)</span> degrees
of freedom. In our case <span class="math inline">\(\alpha=0.05\)</span>
so we need the 97.5% quantile. See for example Chapter 10 of <span
class="citation" data-cites="young_smith2005">Young and Smith
(2005)</span> or the Wikipedia page on <a
href="https://en.wikipedia.org/wiki/Prediction_interval#Unknown_mean,_unknown_variance">prediction
intervals</a> for details.</p>
<p>With <span class="math inline">\(d=15\)</span> <a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> the
upper limit of a one-sided 97.5% prediction interval would have the
multiplication factor 2.22 on the estimated standard deviation. Using a
factor of 2 instead means your procedure is slightly more sensitive than
the possibly anticipated 2.5% false alarm probability. Calculations show
that the false alarm probability under the null hypothesis is 3.7%
(assuming the Gaussian assumption holds). For the sake of simplicity one
can say that this difference in the <span
class="math inline">\(d=15\)</span> case appears ignorable. Had <span
class="math inline">\(d\)</span> been smaller the difference becomes
more relevant though.</p>
<h3 id="reason-3">Reason 3</h3>
<p>I’m not sure I got the point, but one problem is that if your
baseline consists of the observations <span
class="math inline">\(y\)</span>, <span
class="math inline">\(y\)</span>, <span
class="math inline">\(\ldots\)</span>, <span
class="math inline">\(y\)</span> then the upper limit by your method
will also be <span class="math inline">\(y\)</span>, because the
estimated standard deviation will be zero. Another problem is if the
denominator <span class="math inline">\(n_t\)</span> is zero, but
because this appears to have a regular shape (no reports on weekends),
this can just be left out of the modelling?</p>
<h3 id="reason-4">Reason 4</h3>
<p>This reason I find particular troublesome, because it is an argument
statisticians hear often. A wider audience expects a
<strong>valid</strong> statistical method, not more complicated than
necessary, but <strong>sound</strong> and available within the tools at
hand. I argued above that two times standard deviation for proportions
might be working, but you implicitly leave a lot of problems for the
user to solve due to insufficient statistical modelling. I agree that
too complicated might not work, but if -for the sake of pragmatism- we
neither inform or quantify potential problems of a <em>too
simplistic</em> solution nor fail to provide something workable which is
better, we’ll be out of a job quickly.</p>
<h2 id="can-we-do-better">Can we do better?</h2>
<p>Initially it appeared natural to either try a data or parameter
transformation in order to ensure that the computed upper limit respects
the <span class="math inline">\([0,1]\)</span> bound. However, all
suggestions I tried proved problematic one way or the other, e.g., due
to small sample sizes or proportions being zero. Instead, a simple
Bayesian and a simple non-parametric variant are considered.</p>
<h4 id="beta-binomial">Beta-Binomial</h4>
<p>A simple approach is to use a conjugate prior-posterior Bayesian
updating scheme. Letting <span class="math inline">\(\pi_{t_0}\)</span>
be the true underlying proportion at time <span
class="math inline">\(t_0\)</span> which we try to estimate from the
baseline data, we assume a <span
class="math inline">\(\operatorname{Be}(0.5, 0.5)\)</span> prior for it
initially. Observing <span class="math inline">\(y_{t} \sim
\operatorname{Bin}(n_t, \pi_{t_0})\)</span> for <span
class="math inline">\(t=t_0-d, \ldots, t_0-1\)</span>, the posterior for
<span class="math inline">\(\pi_{t_0}\)</span> will be <span
class="math display">\[
\pi_{t_0} | y_{t_0-d},
\ldots, y_{t_0-1} \sim
\operatorname{Be}\left(0.5 + \sum_{t=t_0-d}^{t_0-1} y_t, 0.5 +
\sum_{t=t_0-d}^{t_0-1} (n_t - y_t)\right)
\]</span> One can then show that the posterior predictive distribution
for the next observation, i.e. <span
class="math inline">\(y_{t_0}\)</span>, is <span class="math display">\[
y_{t_0} | y_{t_0-d}, \ldots, y_{t_0-1} \sim
\operatorname{BeBin}\left(n_{t_0}, 0.5 + \sum_{t=t_0-d}^{t_0-1} y_t, 0.5
+ \sum_{t=t_0-d}^{t_0-1} (n_t - y_t)\right),
\]</span> where <span class="math inline">\(\operatorname{BeBin}(n, a,
b)\)</span> denotes the <a
href="https://en.wikipedia.org/wiki/Beta-binomial_distribution">beta-binomial
distribution</a> with size parameter <span
class="math inline">\(n\)</span> and the two shape parameters <span
class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span> implemented in, e.g., the <a
href="https://cran.r-project.org/web/packages/VGAM/index.html"><code>VGAM</code>
package</a>. We then use the upper 97.5% quantile of this distribution
to define the threshold <span class="math inline">\(U_{t_0}\)</span> for
<span class="math inline">\(p_{t_0}\)</span> and sound an alarm if <span
class="math inline">\(p_{t_0} &gt; U_{t_0}\)</span>.</p>
<p>A simple variant of this procedure is to use a <em>plug-in</em> type
prediction interval by obtaining the upper limit as the 97.5% quantile
of the binomial with size parameter <span
class="math inline">\(n_{t_0}\)</span> and probability <span
class="math inline">\(\overline{p}_{t_0}\)</span>. However, this
approach ignores all uncertainty originating from the estimation of
<span class="math inline">\(\pi_{t_0}\)</span> by <span
class="math inline">\(p_{t_0}\)</span> and, hence, is likely to result
in somewhat narrower prediction intervals than the Beta-Binomial
approach.</p>
<h2 id="non-parametric">Non-parametric</h2>
<p>A non-parametric one-sided 97.5% prediction interval <span
class="math inline">\([0, U]\)</span> based on the continuous values
<span class="math inline">\(p_{t_0-39},\ldots, p_{t_0-1}\)</span>
without ties is given as (see e.g. <span class="citation"
data-cites="arts_etal2004">Arts, Coolen, and van der Laan (2004)</span>
or the Wikipedia entry on <a
href="https://en.wikipedia.org/wiki/Prediction_interval#Non-parametric_methods">non-parametric
prediction intervals</a>): <span class="math display">\[
U_{t_0} = \max(p_{t_0-39},\ldots, p_{t_0-1}).
\]</span> Hence, an alarm is flagged if <span
class="math inline">\(p_{t_0}&gt; U_{t_0}\)</span>. This means we simply
compare the current value with the maximum of the baseline values. If we
only have <span class="math inline">\(d=19\)</span> values, then the
interval from zero to the maximum of these values would constitute a
one-sided 95% prediction interval.</p>
<h2 id="simulation-study">Simulation Study</h2>
<p>We consider the false alarm proportion of the suggested method (2
times and 4 times standard deviation, as well as the prediction interval
method and a beta-binomial approach by simulating from a null model,
where <span class="math inline">\(d+1\)</span> observations are iid.
from a binomial distribution <span
class="math inline">\(\operatorname{Bin}(25, \pi)\)</span>. The first
<span class="math inline">\(d\)</span> observations are used for
estimation and then upper limit computed by the algorithm is compared to
the last observations. Note: the non-parametric method requires the
simulation of 39+1 values. For all methods: If the last observation
exceeds the upper limit an alarm is sounded. We will be interested in
the false alarm probability, i.e. the probability that an alarm is
sounded even though we know that the last observation originates from
the same model as the baseline parameters. For the methods using a 97.5%
one-sided prediction interval, we expect this false error probability to
be 2.5%.</p>
<p>The function implementing the six algorithms to compare looks as
follows:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>algo_sysu_all <span class="ot">&lt;-</span> <span class="cf">function</span>(y, n, t0, d) {</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stopifnot</span>(t0<span class="sc">-</span>d <span class="sc">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> y<span class="sc">/</span>n</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  baseline_idx <span class="ot">&lt;-</span> (t0<span class="dv">-1</span>)<span class="sc">:</span>(t0<span class="sc">-</span>d)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  baseline <span class="ot">&lt;-</span> p[baseline_idx]</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  m <span class="ot">&lt;-</span> <span class="fu">mean</span>(baseline)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  sd <span class="ot">&lt;-</span> <span class="fu">sd</span>(baseline)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  U_twosd <span class="ot">&lt;-</span>  m <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>sd</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  U_pred <span class="ot">&lt;-</span> m <span class="sc">+</span> <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">+</span><span class="dv">1</span><span class="sc">/</span>d)<span class="sc">*</span><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df=</span>d<span class="dv">-1</span>)<span class="sc">*</span>sd</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  U_foursd <span class="ot">&lt;-</span>  m <span class="sc">+</span> <span class="dv">4</span><span class="sc">*</span>sd</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="do">##Beta binomial</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  astar <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fu">sum</span>(y[baseline_idx])</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  bstar <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fu">sum</span>((n[baseline_idx] <span class="sc">-</span> y[baseline_idx]))</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  U_betabinom <span class="ot">&lt;-</span> <span class="fu">qbetabinom.ab</span>(<span class="at">q=</span><span class="fl">0.975</span>, <span class="at">size=</span>n[t0], <span class="at">shape1=</span>astar, <span class="at">shape2=</span>bstar) <span class="sc">/</span> n[t0]</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  <span class="do">##Prediction interval based on the Binomal directly, ignoring estimation uncertainty</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  U_binom <span class="ot">&lt;-</span> <span class="fu">qbinom</span>(<span class="at">p=</span><span class="fl">0.975</span>, <span class="at">size=</span>n[t0], <span class="at">prob=</span>m) <span class="sc">/</span> n[t0]</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  <span class="do">##Non-parametric with a 97.5% one-sided PI (this approach needs 39 obs)</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  U_nonpar <span class="ot">&lt;-</span> <span class="fu">max</span>( p[(t0<span class="dv">-1</span>)<span class="sc">:</span>(t0<span class="dv">-39</span>)])</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  <span class="do">##Done</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">data.frame</span>(<span class="at">t=</span>t0, <span class="at">U_twosd=</span>U_twosd, <span class="at">U_foursd=</span>U_foursd, <span class="at">U_pred=</span>U_pred, <span class="at">U_betabinom=</span>U_betabinom, <span class="at">U_nonpar=</span>U_nonpar, <span class="at">U_binom=</span>U_binom))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>This can be wrapped into a function performing a single simulation
:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="do">##Simulate one iid binomial time series</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>simone <span class="ot">&lt;-</span> <span class="cf">function</span>(pi0, <span class="at">d=</span><span class="dv">21</span>, <span class="at">n=</span><span class="dv">25</span>) {</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  length_ts <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="dv">39</span><span class="sc">+</span><span class="dv">1</span>, d<span class="sc">+</span><span class="dv">1</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(length_ts, <span class="at">size=</span>n, <span class="at">prob=</span>pi0)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">rep</span>(n, length_ts)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> y<span class="sc">/</span>n</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">algo_sysu_all</span>(<span class="at">y=</span>y, <span class="at">n=</span>n, <span class="at">t0=</span>length_ts, <span class="at">d=</span>d)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">c</span>(<span class="at">twosd=</span>res<span class="sc">$</span>U_twosd, <span class="at">foursd=</span>res<span class="sc">$</span>U_foursd, <span class="at">pred=</span>res<span class="sc">$</span>U_pred, <span class="at">betabinom=</span>res<span class="sc">$</span>U_betabinom, <span class="at">nonpar=</span>res<span class="sc">$</span>U_nonpar, <span class="at">binom=</span>res<span class="sc">$</span>U_binom) <span class="sc">&lt;</span> p[length_ts])</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We then perform the simulation study using several cores using the <a
href="https://cran.r-project.org/web/packages/future/index.html"><code>future</code></a>
and <a
href="https://cran.r-project.org/web/packages/future/index.html"><code>future.apply</code></a>
packages by <a href="https://twitter.com/henrikbengtsson">Henrik
Bengtsson</a>:</p>
<center>
<img src="/blog/figure/source/2018-10-29-gauss/PLOTFAP-1.png" style="display: block; margin: auto;" />
</center>
<FONT COLOR="bbbbbb">Figure 2: False positive probability for different
<span class="math inline">\(\pi\)</span> values each estimated by 10,000
Monte Carlo simulations. </FONT>
<p>
<p>In the figure we see that both the two and four times standard
deviation approach (twosd, foursd) as well as the approach based on the
97.5% predictive distribution in a Gaussian setting (pred) have a
varying FAP over the range of true proportions: The smaller <span
class="math inline">\(\pi\)</span> the higher the FAP: The FAP can be as
high as 7% instead of the nominal 2.5%. When monitoring 145 time points
this means that we will on average see <span
class="math inline">\(145\cdot 0.07=10\)</span> false alarms, if the
process does not change. This is problematic, because the behaviour of
the detection procedure depends on the underlying <span
class="math inline">\(\pi\)</span>: the user will get way more false
alarm at low <span class="math inline">\(\pi\)</span>’s than possibly
expecting. Altogether, it appears better to use a slightly higher
threshold than 2. However, <span class="math inline">\(k=4\)</span>
looks awfully conservative!</p>
<p>All considered procedures dip down to a FAP of 0% for <span
class="math inline">\(\pi\)</span> near 100%, which means no alarms are
sounded here. This is related to the fact that if <span
class="math inline">\(U_{t_0}=n_{t_0}\)</span> then, because <span
class="math inline">\(p_{t_0} &gt; U_{t_0}\)</span> is required before
an alarm will be sounded, no alarm is possible. Furthermore, both the
beta-binomial, the binomial variant and the non-parametric procedure
have FAPs slightly lower than the nominal 2.5%. This is again related to
the discreteness of the problem: It might not be possible to find an
integer limit <span class="math inline">\(U\)</span> such that the CDF
at <span class="math inline">\(U\)</span> is exactly 97.5%, i.e. usually
<span class="math inline">\(F(q_{0.975})&gt;0.975\)</span>. Because we
only sound alarms if <span class="math inline">\(y_{t_0} &gt;
U\)</span>, i.e. the probability for this to occur is even smaller,
namely, <span class="math inline">\(1-F(q_{0.975}+1)\)</span>.</p>
<p>Note that in the above simulation study the binomial and
beta-binomial models are in advantage, because the model used to
simulate data is identical and closely identical, respectively, to how
data are simulated. In order to make the simulation more comprehensive
we investigate an additional scenario where the marginal distribution
are binomial <span class="math inline">\(\operatorname{Bin}(25,
0.215)\)</span>, but are correlated<a href="#fn3" class="footnote-ref"
id="fnref3" role="doc-noteref"><sup>3</sup></a>. We simulate variables
<span class="math inline">\(y_t^*\)</span> using an <span
class="math inline">\(AR(1)\)</span> process with parameter <span
class="math inline">\(\rho\)</span>, <span class="math inline">\(|\rho|
&lt; 1\)</span>, i.e. <span class="math display">\[
y_t^* | y_{t-1}^* = \rho \cdot y_{t-1}^* + \epsilon_t, \quad
t=2,3,\ldots,
\]</span> where <span class="math inline">\(y_1^* \sim N(0,1)\)</span>
and <span class="math inline">\(\epsilon_t \stackrel{\text{iid}}{\sim}
N(0,1)\)</span>. These latent variables are then marginally
back-transformed to standard uniforms <span class="math inline">\(u_t
\sim U(0,1)\)</span> using the <a
href="https://en.wikipedia.org/wiki/Probability_integral_transform">probability
integral transform</a> and are then transformed using the quantile
function of the <span class="math inline">\(\operatorname{Bin}(25,
0.215)\)</span> distribution, i.e.</p>
<center>
<span class="math inline">\(y_t\)</span> =
<code>qbinom(pnorm(ystar[t]))</code>
</center>
<p>
<p>Altogether, this corresponds to a <a
href="https://stackoverflow.com/questions/10535235/generate-correlated-random-numbers-from-binomial-distributions-in-r#10540234">Gaussian
copula</a> approach for generating correlated random variables with a
given marginal distribution. The correlation between the <span
class="math inline">\(y_t\)</span> will not be exactly <span
class="math inline">\(\rho\)</span> due to the discrete nature of the
binomial, but will approach <span class="math inline">\(\rho\)</span> as
<span class="math inline">\(n\)</span> in the binomial becomes large.
Figure 3 shows the results for the false alarm probability based on
10,000 Monte Carlo simulations for marginal <span
class="math inline">\(\operatorname{Bin}(25, 0.215)\)</span>
distribution and latent <span class="math inline">\(AR(1)\)</span>
one-off-the-diagonal correlation parameter <span
class="math inline">\(\rho\)</span>.</p>
<img src="/blog/figure/source/2018-10-29-gauss/SIMCORRELATED-1.png" style="display: block; margin: auto;" />
</center>
<FONT COLOR="bbbbbb">Figure 3: Equivalent of a false alarm probability
by 10,000 Monte Carlo simulation for the algorithms when there is a
correlation <span class="math inline">\(\rho\)</span> on the latent
scale, but the marginal mean of all observations is <span
class="math inline">\(\pi=0.215\)</span>. </FONT>
<p>
<p>We see that the binomial and beta binomial approaches sound too many
alarms as the correlation increases. Same goes for the two times
standard deviation and the predictive approach. The non-parametric
approach appears to behave slightly better.</p>
<h2 id="application">Application</h2>
<p>We use the <strong>synthetic acute respiratory infection
data</strong> made available as part of the paper’s SySu Excel tool
available for <a
href="https://www.rki.de/DE/Content/Gesundheitsmonitoring/Gesundheitsberichterstattung/GesundAZ/Content/A/Asylsuchende/SynSurv/SynSurv_Tab_gesamt.html">download</a>
under a creative common license. In what follows we focus on the time
series for the symptom <em>acute respiratory infections</em>. Figure
shows the daily proportions 2017-01-01 until 2017-07-20 for all weekdays
as vertical bars with the monitoring starting at time point 40. Also
shown is the upper threshold <span class="math inline">\(U_t\)</span>
for six methods discussed above.</p>
<center>
<img src="/blog/figure/source/2018-10-29-gauss/PLOTALLMONITORING-1.png" style="display: block; margin: auto;" />
</center>
<FONT COLOR="bbbbbb">Figure 4: Upper bound curves for all detection
procedures.</FONT>
<p>
<p>The correlation between <span class="math inline">\(p_{t}\)</span>
and <span class="math inline">\(p_{t-1}\)</span> in the time series is
0.04, which could be a sign that the synthetic were artificially
generated using an independence assumption.</p>
<p>For all algorithms we see the effect on the upper threshold as spikes
enter the baseline. In particular the non-parametric method, which uses
<span class="math inline">\(d=39\)</span> baseline values, will only
sound an alarm during 39 days after time 60, if the proportion is larger
than the <span class="math inline">\(p_{60} = 69.6\)</span> percent
spike.</p>
<h2 id="discussion">Discussion</h2>
<p>This post discussed how to use statistical process control in order
to monitor a proportion within a syndromic surveillance context. The
suitability and performance of Gaussian approximations was discussed: It
was shown that the false alarm probability for this approach depends on
the level of the considered proportion and that auto-correlation also
has a substantial impact on the chart. The investigation in this post
were done in order to provide the user of such charts with a guidance on
how to choose <span class="math inline">\(k\)</span>.</p>
<p>Altogether, a full scientific analysis would need a more
comprehensive simulation study and likely access to the real data, but
the point of this post was to substantiate that statistical problems
need a statistical investigation. From the simulation results in this
post it appears more prudent to use <span
class="math inline">\(k&gt;2\)</span>, e.g., the upper limit of a 97.5%
one-sided prediction interval (<span
class="math inline">\(k\)</span>=2.22) or the upper limit of a 99.5%
one-sided prediction interval (<span
class="math inline">\(k\)</span>=3.07). Choosing <span
class="math inline">\(k&gt;2\)</span> is also supported by the fact that
<span class="citation" data-cites="sarma_etal2018">Sarma et al.
(2018)</span> report that none of the 204 signals generated by the
system were subsequently interpreted as an outbreak. Furthermore, a
simple fix to avoid confusion could be to chop the upper threshold at
100% in the graphics, i.e. to report <span class="math inline">\(U_t^* =
\max(1, U_t)\)</span> for the Gaussian based procedures. Better would be
to use the predictive approach and let the user choose <span
class="math inline">\(\alpha\)</span> and thus give the parameter choice
a probabilistic interpretation. However, binomial and beta-binomial
based approaches provide more stable results over the full range of
<span class="math inline">\(\pi\)</span> and are guaranteed to respect
the <span class="math inline">\([0,1]\)</span> support. In particular
the <strong>non-parametric method looks promising</strong> despite being
even simpler than the proposed k-sd-system. All in all, addressing
trends or other type of auto-correlation as well as previous outbreaks
in the baseline appears to be important in order to get a more specific
syndromic surveillance system - see Sect. 3.4 of <span class="citation"
data-cites="salmon_etal2016a">Salmon, Schumacher, and Höhle
(2016)</span> for how this could look. I invite you to read the <span
class="citation" data-cites="sarma_etal2018">Sarma et al. (2018)</span>
paper to form your own opinion.</p>
<h4 id="acknowledgments">Acknowledgments</h4>
<p>The contents of this post were discussed as part of the ht2018
Statistical Consultancy M.Sc. course at the Department of Mathematics,
Stockholm University. I thank Jan-Olov Persson, Rolf Sundberg and the
students of the course for their comments, remarks and questions.</p>
<h4 id="conflict-of-interest">Conflict of Interest</h4>
<p>I have previously worked for the Robert Koch Institute. Some of the
co-authors of the <span class="citation"
data-cites="sarma_etal2018">Sarma et al. (2018)</span> paper are
previous colleagues, which I have published together with.</p>
<h2 class="unnumbered" id="literature">Literature</h2>
<div id="refs" class="references csl-bib-body hanging-indent"
role="list">
<div id="ref-arts_etal2004" class="csl-entry" role="listitem">
Arts, G. R. J., F. P. A. Coolen, and P. van der Laan. 2004.
<span>“Nonparametric Predictive Inference in Statistical Process
Control.”</span> <em>Quality Technology &amp; Quantitative
Management</em> 1 (2): 201–16.
</div>
<div id="ref-fricker_etal2008" class="csl-entry" role="listitem">
Fricker, R. D., B. L. Hegler, and D. A. Dunfee. 2008. <span>“<span
class="nocase"><span>C</span>omparing syndromic surveillance detection
methods: <span>E</span><span>A</span><span>R</span><span>S</span>’
versus a
<span>C</span><span>U</span><span>S</span><span>U</span><span>M</span>-based
methodology</span>.”</span> <em>Stat Med</em> 27 (17): 3407–29.
</div>
<div id="ref-salmon_etal2016a" class="csl-entry" role="listitem">
Salmon, M., D. Schumacher, and M. Höhle. 2016. <span>“Monitoring Count
Time Series in <span>R</span>: Aberration Detection in Public Health
Surveillance.”</span> <em>Journal of Statistical Software</em> 70 (10).
<a
href="https://doi.org/10.18637/jss.v070.i10">https://doi.org/10.18637/jss.v070.i10</a>.
</div>
<div id="ref-sarma_etal2018" class="csl-entry" role="listitem">
Sarma, N., A. Ullrich, H. Wilking, S. Ghozzi, A. K. Lindner, C. Weber,
A. Holzer, A. Jansen, K. Stark, and S. Vygen-Bonnet. 2018. <span>“<span
class="nocase"><span>S</span>urveillance on speed: <span>B</span>eing
aware of infectious diseases in migrants mass accommodations - an easy
and flexible toolkit for field application of syndromic surveillance,
<span>G</span>ermany, 2016 to 2017</span>.”</span> <em>Euro
Surveill.</em> 23 (40).
</div>
<div id="ref-young_smith2005" class="csl-entry" role="listitem">
Young, G. A., and R. L. Smith. 2005. <em>Essentials of Statistical
Inference</em>. Cambridge University Press.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The method contains two additional parameters: one being
the minimum number of cases needed on a particular day to sound an alarm
(low-count protection) and a fixed threshold for the proportion beyond
which a signal was always created. For the sake of statistical
investigation we shall disregard these two features in the analysis of
this post.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In the paper d=21 was used, but due to many missing
values, e.g., due to weekends, the actual number of observations used
was on average 15. We therefore use <span
class="math inline">\(d=15\)</span> in the blog post.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The 21.5% is taken from Table 2 of <span
class="citation" data-cites="sarma_etal2018">Sarma et al. (2018)</span>
for acute respiratory infections.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

  </div>

</article>

	

<!-- Add Disqus comments. -->
<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     **/
    /**
    var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    **/
    var disqus_config = function () {
      this.page.url = "https://mhoehle.github.io/blog/2018/10/29/gauss.html";
      this.page.identifier = "/2018/10/29/gauss";
    };
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');

        s.src = '//hoehle.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>



      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Theory meets practice...</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Theory meets practice...</li>
          <li><a href="https://math-inf.uni-greifswald.de/en/michael-hoehle/">Michael Höhle</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/mhoehle"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">mhoehle</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/m_hoehle"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">m_hoehle</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>A blog about statistics in theory and practice. Not always serious, not always flawless, but definitely a statistically flavoured bean.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
